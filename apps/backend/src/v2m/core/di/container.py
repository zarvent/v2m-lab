# This file is part of voice2machine.
#
# voice2machine is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# voice2machine is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with voice2machine.  If not, see <https://www.gnu.org/licenses/>.

"""
Contenedor de Inyecci√≥n de Dependencias (DI) para Voice2Machine.

Este m√≥dulo implementa el patr√≥n de Inyecci√≥n de Dependencias que conecta
toda la aplicaci√≥n. Es el √∫nico lugar donde las implementaciones concretas
son conocidas y donde se decide qu√© implementaci√≥n usar para cada interfaz.

Responsabilidades del Contenedor:
    1. **Instanciar Servicios de Infraestructura**: Crea las implementaciones
       concretas como singletons (WhisperService, GeminiService, etc.).
    2. **Instanciar Handlers de Aplicaci√≥n**: Crea los Command Handlers
       inyect√°ndoles las dependencias que necesitan.
    3. **Configurar el CommandBus**: Registra todos los handlers para que
       el bus sepa a qui√©n despachar cada tipo de comando.

Beneficios:
    - **Desacoplamiento**: Los handlers dependen de interfaces, no de implementaciones.
    - **Testabilidad**: Es f√°cil sustituir servicios reales por mocks en los tests.
    - **Configurabilidad**: Cambiar implementaciones (ej. Gemini -> OpenAI)
      solo requiere modificar este archivo o la configuraci√≥n.

Diagrama de Dependencias:
    ::

        Container
        ‚îú‚îÄ‚îÄ VADService
        ‚îú‚îÄ‚îÄ WhisperTranscriptionService (usa VADService)
        ‚îú‚îÄ‚îÄ GeminiLLMService
        ‚îú‚îÄ‚îÄ LinuxNotificationAdapter
        ‚îú‚îÄ‚îÄ LinuxClipboardAdapter
        ‚îú‚îÄ‚îÄ StartRecordingHandler (usa Transcription, Notification)
        ‚îú‚îÄ‚îÄ StopRecordingHandler (usa Transcription, Notification, Clipboard)
        ‚îú‚îÄ‚îÄ ProcessTextHandler (usa LLM, Notification, Clipboard)
        ‚îî‚îÄ‚îÄ CommandBus (registra todos los handlers)

Ejemplo:
    Acceso al contenedor desde otros m√≥dulos:

    ```python
    from v2m.core.di.container import container

    bus = container.get_command_bus()
    await bus.dispatch(MiComando())
    ```
"""

import asyncio
import os
from concurrent.futures import ThreadPoolExecutor

from v2m.application.command_handlers import ProcessTextHandler, StartRecordingHandler, StopRecordingHandler
from v2m.application.llm_service import LLMService
from v2m.application.transcription_service import TranscriptionService
from v2m.config import config
from v2m.core.cqrs.command_bus import CommandBus
from v2m.core.interfaces import ClipboardInterface, NotificationInterface
from v2m.core.logging import logger
from v2m.core.providers import ProviderNotFoundError, llm_registry, transcription_registry
from v2m.infrastructure.gemini_llm_service import GeminiLLMService
from v2m.infrastructure.linux_adapters import LinuxClipboardAdapter
from v2m.infrastructure.local_llm_service import LocalLLMService
from v2m.infrastructure.notification_service import LinuxNotificationService
from v2m.infrastructure.ollama_llm_service import OllamaLLMService

# --- AUTO-REGISTRO DE PROVEEDORES ---
# Los imports fuerzan el registro en los registries globales.
# Esto permite que el container resuelva providers din√°micamente desde config.
from v2m.infrastructure.whisper_transcription_service import WhisperTranscriptionService

# Registrar providers expl√≠citamente (m√°s claro que auto-registro v√≠a decorador)
transcription_registry.register("whisper", WhisperTranscriptionService)
llm_registry.register("local", LocalLLMService)
llm_registry.register("gemini", GeminiLLMService)
llm_registry.register("ollama", OllamaLLMService)


class Container:
    """
    Contenedor de DI que gestiona el ciclo de vida y las dependencias de los objetos.

    El contenedor es instanciado una √∫nica vez al inicio de la aplicaci√≥n
    y proporciona acceso a los servicios configurados durante toda la
    ejecuci√≥n del programa.

    Atributos:
        transcription_service: Servicio de transcripci√≥n (faster-whisper).
        llm_service: Servicio de LLM para refinamiento de texto (Gemini, Local, Ollama).
        notification_service: Adaptador de notificaciones del sistema.
        clipboard_service: Adaptador del portapapeles del sistema.
        start_recording_handler: Handler para el comando StartRecording.
        stop_recording_handler: Handler para el comando StopRecording.
        process_text_handler: Handler para el comando ProcessText.
        command_bus: Bus de comandos configurado con todos los handlers.
    """

    def __init__(self) -> None:
        """
        Inicializa y configura todas las dependencias de la aplicaci√≥n.

        El proceso de configuraci√≥n sigue estos pasos:

        1. **Servicios de Infraestructura** (como Singletons):
           Se crean las implementaciones concretas de los servicios.
           Aqu√≠ se decide qu√© implementaci√≥n usar para cada interfaz.

        2. **Handlers de Aplicaci√≥n**:
           Se crean los manejadores de comandos inyect√°ndoles las
           dependencias que necesitan para funcionar.

        3. **CommandBus**:
           Se configura el bus registrando todos los handlers para que
           sepa a cu√°l despachar cada tipo de comando.

        Nota:
            El modelo Whisper se precarga en un hilo de fondo para evitar
            latencia en la primera transcripci√≥n. Si falla la precarga,
            se cargar√° bajo demanda en el primer uso.
        """
        # --- 1. Instanciar Servicios (como Singletons) ---
        # Resoluci√≥n din√°mica desde registries seg√∫n config.toml

        # --- Selecci√≥n de backend de transcripci√≥n seg√∫n configuraci√≥n ---
        transcription_backend = config.transcription.backend
        try:
            TranscriptionClass = transcription_registry.get(transcription_backend)
            self.transcription_service: TranscriptionService = TranscriptionClass()
            logger.info(f"backend de transcripci√≥n seleccionado: {transcription_backend}")
        except ProviderNotFoundError as e:
            logger.critical(f"backend de transcripci√≥n inv√°lido: {e}")
            raise

        # ThreadPoolExecutor para warmup - libera el GIL mejor que threading.Thread
        # porque permite que el event loop siga procesando durante la carga
        self._warmup_executor = ThreadPoolExecutor(max_workers=1, thread_name_prefix="warmup")
        self._warmup_future = self._warmup_executor.submit(self._preload_models)

        # --- Selecci√≥n de backend LLM seg√∫n configuraci√≥n ---
        llm_backend = config.llm.backend
        try:
            LLMClass = llm_registry.get(llm_backend)
            self.llm_service: LLMService = LLMClass()
            logger.info(f"backend llm seleccionado: {llm_backend}")
        except ProviderNotFoundError as e:
            logger.critical(f"backend llm inv√°lido: {e}")
            raise

        # Adaptadores de Sistema
        self.notification_service: NotificationInterface = LinuxNotificationService()
        self.clipboard_service: ClipboardInterface = LinuxClipboardAdapter()

        # --- 2. Instanciar Manejadores de Comandos ---
        # Se inyectan las dependencias en el constructor de cada handler
        self.start_recording_handler = StartRecordingHandler(self.transcription_service, self.notification_service)
        self.stop_recording_handler = StopRecordingHandler(
            self.transcription_service, self.notification_service, self.clipboard_service
        )
        self.process_text_handler = ProcessTextHandler(
            self.llm_service, self.notification_service, self.clipboard_service
        )

        # --- 3. Instanciar y Configurar el Bus de Comandos ---
        # El bus de comandos se convierte en el punto de acceso central para
        # ejecutar la l√≥gica de negocio
        self.command_bus = CommandBus()
        self.command_bus.register(self.start_recording_handler)
        self.command_bus.register(self.stop_recording_handler)
        self.command_bus.register(self.process_text_handler)

    def get_command_bus(self) -> CommandBus:
        """
        Proporciona acceso al CommandBus configurado.

        Este es el punto de acceso principal para despachar comandos.
        El bus ya tiene todos los handlers registrados y est√° listo para usar.

        Returns:
            CommandBus: La instancia √∫nica del bus con todos los handlers
            registrados.
        """
        return self.command_bus

    def _preload_models(self) -> None:
        """
        Precarga modelos de ML en segundo plano para reducir latencia del primer uso.

        Se ejecuta en ThreadPoolExecutor para no bloquear el event loop.
        La carga de Whisper involucra:
        - Descarga/verificaci√≥n del modelo (~1-2GB).
        - Asignaci√≥n de VRAM en GPU.
        - Compilaci√≥n de kernels CUDA (primera vez).
        """
        # SOTA 2026: Lazy Load para optimizaci√≥n de recursos extrema
        # Permite iniciar la app en 50ms si no se va a usar inmediatamente
        lazy = config.transcription.lazy_load or os.getenv("LAZY_LOAD") == "1"
        if lazy:
            logger.info("üí§ lazy load activado: modelos se cargar√°n bajo demanda")
            return

        try:
            # Precargar Whisper (el m√°s pesado)
            _ = self.transcription_service.model
            logger.info("‚úÖ whisper precargado correctamente")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è no se pudo precargar whisper: {e}")

    async def wait_for_warmup(self, timeout: float = 30.0) -> bool:
        """
        Espera a que los modelos terminen de cargar (async-safe).

        Args:
            timeout: Tiempo m√°ximo de espera en segundos.

        Returns:
            bool: True si la carga fue exitosa, False si hubo timeout.
        """
        loop = asyncio.get_event_loop()
        try:
            await asyncio.wait_for(loop.run_in_executor(None, self._warmup_future.result), timeout=timeout)
            return True
        except TimeoutError:
            logger.warning(f"timeout de warmup despu√©s de {timeout}s")
            return False


# --- Instancia Global del Contenedor ---
# Se crea una √∫nica instancia del contenedor que ser√° accesible desde toda la
# aplicaci√≥n (principalmente desde `main.py`).
container = Container()
